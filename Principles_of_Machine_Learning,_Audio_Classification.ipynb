{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Principles_of_Machine_Learning,_Audio_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Task"
      ],
      "metadata": {
        "id": "Ao8i9AN6GTEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to build a pipeline for classifying humming or whistling audio clips as being for the Harry Potter or for the StarWars theme tune.\n",
        "\n",
        "The dataset used is the MLEnd Hums and Whistles dataset. For more information on this please visit https://lnkd.in/eqAiwu23 "
      ],
      "metadata": {
        "id": "ikoxDhPd901V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Pipeline"
      ],
      "metadata": {
        "id": "ETP8iMW_GO3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We experiment with various architectures. For each we review the validation accuracy and use this to decide on the final pipeline. Our final pipeline:\n",
        "\n",
        "\n",
        "\n",
        "*   Split each audio file input into two halves\n",
        "*   Extract the tempo feature for each half\n",
        "*   Input the extracted features into an SVM model with C=1 predicting if an input has a Potter or a StarWars label\n",
        "\n"
      ],
      "metadata": {
        "id": "NoiRAgfmFV_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the Audio File\n",
        "\n",
        "We will split each audio signal in half.\n",
        "\n",
        "From the coursework explanation notebook and [1] we have \n",
        "\n",
        "`x, fs = librosa.load(files[n],sr=fs)`\n",
        "\n",
        "and for two sections:\n",
        "\n",
        "```\n",
        "x1 = x[0:int(0.5*len(x))]\n",
        "\n",
        "x2 = x[int(0.5*len(x)):int(len(x))]\n",
        "```"
      ],
      "metadata": {
        "id": "KGmmuVjfGXvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting the Tempo Feature\n",
        "\n",
        "We refer to [2] for information on tempo. \n",
        "\n",
        "```\n",
        "#example\n",
        "n = 5\n",
        "fs = None\n",
        "x, fs = librosa.load(files[n],sr=fs)\n",
        "tempo = librosa.beat.tempo(x,sr=fs)\n",
        "print(tempo)\n",
        "print(sum(tempo))\n",
        "```\n",
        "\n",
        "We will use the sum here so to return a single value rather than a single term list - we will refer to the sum of the tempo output as just the tempo. From the librosa documentation, since we are not setting the aggregate hyperparameter to 'None', we get one overall tempo value rather than the value for each frame.[2]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5UHLEsOcG7pO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Machine Learning Model**\n",
        "\n",
        "**Support Vector Models** - We will use an SVM model and experiment with varying the kernel and the regularisation [3]. We know that it is unlikely that we will find a set of features which are linearly separable for the Potter and StarWars audio files and so using an SVM model is a good option since there is the option to experiment with using a kernel to map the data to a new space where it might be linearly separable. Also, reducing the regularisation to less than one means that we have a less precise boundary for the classifier - this could be useful since there is likely to be some outlier training samples and if we tried to fit a boundary to all of the training samples we would end up with a boundary that does not work well more generally [4] , [5]. We will experiment with C = 1 and C = 0.9 and kernel = 'rbf' (default), kernel = 'linear', kernel = 'poly' and kernel = 'sigmoid'.\n",
        "\n",
        "Note: in this notebook we have only included the model with the final chosen hyperparameters."
      ],
      "metadata": {
        "id": "5qZHAl0MI4pK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Code"
      ],
      "metadata": {
        "id": "iYhRH1F0JzkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will not run without the required data, given the correct titles.\n",
        "\n",
        "`filescombinedTrain` contains approx 70% of the Potter files and 70% of the StarWars files\n",
        "\n",
        "`filescombinedTest` contains approx 30% of the Potter files and 30% of the StarWars files.\n",
        "\n",
        "` filesPOTTER ` is all the Potter files \n",
        "\n",
        "` filesSTARWARS ` is all the StarWars files \n",
        "\n",
        "note: we referred to [6] to take a sample of one of the sets of files so that we had the same amount of Potter and StarWars files.\n",
        "\n"
      ],
      "metadata": {
        "id": "mTOzj5qxKvjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "pEjUqlrtW4Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is an updated version of the code provided in Principles of Machine Learning Module, Queen Mary University of London\n",
        "\n",
        "def getXy(s,files): \n",
        "  X,y =[],[]\n",
        "  for file in files:\n",
        "    yi = file in filesPOTTER #True if file is in Potter folder, otherwise false, reference [7]\n",
        "\n",
        "\n",
        "    fs = None  #[1]\n",
        "    x, fs = librosa.load(file,sr=fs)\n",
        "    \n",
        "    xi = []\n",
        "\n",
        "    for j in range(s): \n",
        "      xj = x[int((j/s)*len(x)):int(((j+1)/s)*len(x))]  \n",
        "      tempo_j = sum(librosa.beat.tempo(xj,sr=fs)) #[2]\n",
        "      xi.append(tempo_j) #the tempo feature for each of the s sections of the audio \n",
        "\n",
        "\n",
        "    X.append(xi)\n",
        "    y.append(yi)\n",
        "\n",
        "  return np.array(X),np.array(y)"
      ],
      "metadata": {
        "id": "afAlMe7RLeNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is an updated version of the code provided in Principles of Machine Learning Module, Queen Mary University of London\n",
        "\n",
        "X_train,y_train = getXy(2,filescombinedTrain)"
      ],
      "metadata": {
        "id": "7X4JoZ-tLuUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is an updated version of the code provided in Principles of Machine Learning Module, Queen Mary University of London\n",
        "\n",
        "X_test,y_test = getXy(2,filescombinedTest)"
      ],
      "metadata": {
        "id": "RgY-2-VOL24L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#referred to [3], [8], [9] and code provided in Principles of Machine Learning Module, Queen Mary University of London\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model  = svm.SVC(C=1)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_test)\n",
        "\n",
        "print('Training Accuracy', accuracy_score(y_train,yt_p))\n",
        "print('Test Accuracy', accuracy_score(y_test,yv_p))"
      ],
      "metadata": {
        "id": "z-x_upkeL-nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "[1] https://librosa.org/doc/0.9.1/generated/librosa.load.html?highlight=librosa%20load#librosa.load , Brian McFee, Alexandros Metsai, Matt McVicar, Stefan Balke, Carl Thomé, Colin Raffel, Frank Zalkow, Ayoub Malek, Dana, Kyungyun Lee, Oriol Nieto, Dan Ellis, Jack Mason, Eric Battenberg, Scott Seyfarth, Ryuichi Yamamoto, viktorandreevichmorozov, Keunwoo Choi, Josh Moore, … Thassilo. (2022). librosa/librosa: 0.9.1 (0.9.1). Zenodo. https://doi.org/10.5281/zenodo.6097378\n",
        "\n",
        "[2] https://librosa.org/doc/latest/generated/librosa.beat.tempo.html#librosa.beat.tempo , Brian McFee, Alexandros Metsai, Matt McVicar, Stefan Balke, Carl Thomé, Colin Raffel, Frank Zalkow, Ayoub Malek, Dana, Kyungyun Lee, Oriol Nieto, Dan Ellis, Jack Mason, Eric Battenberg, Scott Seyfarth, Ryuichi Yamamoto, viktorandreevichmorozov, Keunwoo Choi, Josh Moore, … Thassilo. (2022). librosa/librosa: 0.9.1 (0.9.1). Zenodo. https://doi.org/10.5281/zenodo.6097378\n",
        "\n",
        "[3] scikit-learn developers (BSD License), sklearn.svm.SVC, scikit-learn, 2007-2021, https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html (accessed 10th December 2021)\n",
        "\n",
        "[4] Using information from Data Mining Module, Queen Mary University of London\n",
        "\n",
        "[5] scikit-learn developers (BSD License), 1.4.6. Kernel functions, scikit-learn, 2007-2021, https://scikit-learn.org/stable/modules/svm.html#svm-kernels (accessed 10th December 2021)\n",
        "\n",
        "[6] Python Software Foundation, random - Generate pseudo-random numbers, Python, 2001-2021, https://docs.python.org/3/library/random.html?highlight=random%20sample \n",
        "\n",
        "[7] W3Schools, Python Booleans, 1999-2022, https://www.w3schools.com/python/python_booleans.asp (accessed 8th June 2022)\n",
        "\n",
        "[8] datacamp, Support Vector Machines with Scikit-learn Tutorial, 2019, https://www.datacamp.com/tutorial/svm-classification-scikit-learn-python \n",
        "\n",
        "[9] scikit-learn developers (BSD License), sklearn.metrics.accuracy_score, 2007-2022, https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html "
      ],
      "metadata": {
        "id": "lCX6MbylCke-"
      }
    }
  ]
}